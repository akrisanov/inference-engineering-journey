# 2025-08-05, Tuesday

## ğŸ¯ Goals for Today

- [x] Continue reading [Fastbook: Chapter 1, Intro](https://colab.research.google.com/github/fastai/fastbook/blob/master/01_intro.ipynb)

## ğŸ“– What I Studied

- [What is Machine Learning](../theory/What%20is%20Machine%20Learning.md)
- [What Is a Neural Network](../theory/What%20Is%20a%20Neural%20Network.md)
- [Labeling Data](../theory/Labeling%20Data.md)
- [Classification and Regression](../theory/Classification%20and%20Regression.md)
- [Metrics](../theory/Metrics.md)
- [CNNs](../theory/CNNs.md)

## ğŸ’¡ Insights and Reflections

- *Overfitting* is the single most important and challenging issue when training for all machine learning practitioners, and all algorithms
- Don't apply methods to avoid overfitting until you have confirmed that *overfitting* is happening (e.g. the validation accuracy getting worse during training)
- Picking a model architecture (such as ResNet) isn't very important part of the deep learning process â†’ use standing architectures that work most of the time
- The `34` in `resnet34` refers to the number of layers in this architecture
  - Other options are `19`, `50`, `101`, and `152`.
  - **More layers â†’ longer to train & more chance of overfitting**
  - *With more data more layers can improve accuracy*
- Don't underestimate usage of pretrained models

## â“ Questions

- What is the difference between loss function and a metric function?
